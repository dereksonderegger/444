# R Packages

## Introduction

R packages are documented and consistent format for storing data, functions, documentation, and analysis. We use a consistent format so that other researchers (or ourselves in six months) know exactly where the raw data should be, where to find any functions that are written, and document the data cleaning process.

In principle, all of these steps could be accomplished by a single data file and a single analysis Rmarkdown file. However as projects get larger in scope, the number of data files, the complexity of data cleaning, and the number of people working with the data will grow. With more complexity, the need to impose order on it becomes critical.

Even if the project is small, organizing my work into a package structure provides a benefit. First, it forces me to keep my data wrangling code organized and encourages documenting any functions I create. Second, by separating the data wrangling step code from the analysis, I think more deeply about verification and initial exploration to understand how best to store the data. Finally, because all my subsequent analysis will depend on the same tidy dataset, I make few mistakes where I cleaned the data correctly in one analysis, but forgot a step in another analysis.

I recommend using an R package for any analysis more complicated than a homework assignment because the start-up is relatively simple and if the project grows, you'll appreciate that you started it in an organized fashion.



### Useful packages and books

There are several packages that make life easier.

| Package    |         Description             |
|:----------:|:--------------------------------|
| `devtools` |  Tools by Hadley, for Hadley (and the rest of us). |
| `roxygen2` |  A coherent documentation syntax |
| `testthat` |  Quality Assurance tools         |
| `usethis`  |  Automates repetitive tasks that arise during project setup and development, both for R packages and non-package projects. |


Hadley Wickham has written a book on R packages that gives a lot more information than I'm giving here. The book is available [online](http://r-pkgs.had.co.nz).


## Package Structure

### Minimal files and directories

|  File/Directory   |                   Description                      |
|:-----------------:|:---------------------------------------------------|
| `DESCRIPTION` | A file describing your package. You **should** edit this at some point. |
| `NAMESPACE`   | A file that lists all the functions and datasets available to users after loading the package. You **should not**  edit this by hand. |
| `.Rbuildignore` | A list of files that shouldn't be included when the package is built. |
| `R/`            | This directory contains documentation files for datasets. It also contains the R code and documention for functions you create. I generally recommend one documentation file for each dataset, and one file for each function, although if you have several related functions, you might keep them in the same file. This directory can be empty, but it does have to exist. |
| `man/`    | This contains the documentation (manual) files generated by `roxygen2`. You **should not** edit these as they will be rebuilt from the source R code in the `R/` directory. |

### Optional Files and Directories

|  File/Directory   |                   Description                      |
|:-----------------:|:---------------------------------------------------|
| `data/` |  A directory of datasets. Each file should be an `.RData` or `.Rda` file created by the `save()` containing a single object (with the same names as the file).  Anything in this directory will be loaded and accessible to the user when the package is loaded. While it isn't necessary for this directory to exist, it often does. |
| `data-raw/` | A directory where we store data files that are not `.RData` format. Usually these are `.csv` or `.xls` files. Typically I'll have R scripts in this directory that read in raw data, do whatever data wrangling and cleaning that needs to be done, and saves the result in the `data/` directory. Obnoxiously the documentation for the dataset does not live in this directory, but rather in the `R/` directory. |
| `docs/` | A directory where any Rmarkdown analysis files that are especially time consuming and should not be executed each time the package is built. When I build a package for a data-analysis project, the reports I create go into this directory. |
| `vignettes/` | A directory where Rmarkdown files should go that introduce how to use the package. When a package is built, then Rmarkdown files in this directory will also be rebuilt.  |
| `tests/` |  A directory for code used for package testing functions you've written.  |
| `inst/`  |  Miscellaneous stuff. In particular `inst/extdata/` is where you might put data that is not in `.RData` format (Excel files and such) but you want it available to the users. Anything in the `inst/extdata` will be available to to user via `system.file('file.xls',package='MyAwesomePackage')` |
| `src/`  |  A directory where C/C++, Fortran, Python, etc source code is stored.  |
| `exec/` | A directory where executables you might have created from the source code should go. |


## Documenting 

The `man/` directory is where the final documentation exists, but the format that was initially established is quite unwieldy. To address this, the `roxygen2` package uses a more robust and modern syntax and keeps the function documentation with the actual code in the `R\` directory. The results in a process where we write the documentation in files in the `R/` directory and then run a `roxygen2` command to build the actual documentation files in the `man/` directory. To run this, use the `Build` tab and then `More -> Document`.

Hadley Wickham has a more complete discussion of package documentation in a
[vignette](https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html) 
for `roxygen2`. If/when the information in this chapter seems insufficient, that should be your next resource.

The documentation information is built in comments and so documentation lines always start with a `#'`. For both datasets and functions, the first couple of lines give the short title and description. 


```r
#' A short title
#' 
#' A longer paragraph that describes the context of the dataset/function and 
#' discusses important aspects that will be necessary for somebody first seeing 
#' the data/function to know about. Any text in these initial paragraphs will be 
#' in the description section of the documentation file.
#' 
```


### Dataset Documentation
Dataset documentation should contain both general information about the context of the data as well as detailed information about the data columns. Finally the documentation should also include information about where the data came from, if it is available. The title and description are given in the first paragraphs of the description, but the format and source need some indication starting the sections.


```r
#' @format A data frame with XXX observations with ZZ columns.
#' \describe{
#'    \item{Column1}{Description of column 1, including units if appropriate}
#'    \item{Column2}{Description of column 2, including units if appropriate}
#' }
```

There are a few other documentation sections that can be filled in. They will all be introduced using `@Section` notation.

```r
#' @source This describes where the data came from
#' @references If we need to cite some book or journal article.
```



### Documenting Functions
Functions that you want other people to use need to be documentated. In particular, we need a general description of what the function does, a list of all function arguments and what they do, and what type of object the function returns. Finally, it is nice to have some examples that demonstrate how the function can be used.


```r
#' Sum two numeric objects.
#'
#' Because this is a very simple function, my explanation is short. These
#' paragraphs should explain everything you need to know.
#' 
#' This is still in the description part of the documentation and and it 
#' will be until we see something that indicates a new section.
#'
#' @param a A real number
#' @param b A real number
#' @return The sum of \code{a} and \code{b}
#' @examples
#' sum(12,5)
#' sum(4,-2)
#' @export
my.sum <- function( a, b ){
  return( a + b )
}
```

Each of the sections is self explanatory except for the `@export`. The purpose of this is to indicate that this function should be available to any user of the package. If a function is not exported, then it is available only to functions *within* the package. This can be convenient if there are multiple functions that help with the analysis but you don't want the user to see them because it is too much work to explain that they shouldn't use it

Other regions that you might use: 
* `@seealso` allows you to point to other resources 
    + on the web `\url{http://www.r-project.org}`
    + in your package `\code{\link{hello}}`
    + in another package `\code{\link[package]{function}}`
* `@aliases alias_1 alias_2 ...` Other topics that when searched for will point to this documentation
* `@author` This isn't necessary if the author is the same as the package author.
* `@references` This is a text area to point to the literature.





## The DESCRIPTION file
I never write the DESCRIPTION file myself, but rather it is generated it from a template when the package structure is initially created. It is useful to go into this file and edit it. 

```r
Package: MyAwesomePackage
Title: What the Package Does (One Line, Title Case)
Version: 0.0.0.9000
Authors@R: 
    person(given = "First",
           family = "Last",
           role = c("aut", "cre"),
           email = "first.last@example.com",
           comment = c(ORCID = "YOUR-ORCID-ID"))
Description: What the package does (one paragraph).
License: What license it uses
Encoding: UTF-8
LazyData: true
```

Often you want to have your package include other libraries so that the packages are available to be used in any functions you use. To do this, you'll add lines to the description file. 
    
    ```r
    Depends: magrittr     
    Imports: dplyr, ggplot2, tidyr
    Suggests: lme4
    ```

In this example, I've included a dependency on the `magrittr` package, which defines the `%>%` operator, while `dplyr`, `ggplot2`, `tidyr`, and `lme4` packages are included in a slightly different manner.

|  Package Dependency Type |                                  Description                |
|:----------------------:|:------------------------------------------------------------|
| `Depends` |  These packages are required to have been downloaded from CRAN and will be attached to the namespace when your package is loaded. If your package is going to be widely used, you want to keep this list as short as possible to avoid function name clashes.  |
| `Imports` |  These packages are required be present on the computer, but will **not** be attached to the namespace.  Whenever you want to use them you must use then in one of your functions, you'll need to use `PackageName::FunctionName` syntax.  |
| `Suggests` | These packages are not required. Often these are packages of data that are only used in the examples, the unit tests, or in a vignette. These are not loaded/attached by default. |

For widely distributed packages, using `Imports` is preferred but that is annoying to be required to use the `PackageName::FunctionName()` syntax within all of the functions you write. The reason to avoid Depends is to avoid namespace problems. For example, because packages `MASS` and `dplyr` both have a `select()` function, it is advisable to avoid depending on `dplyr` just in case the user also has loaded the `MASS` package. 

For a data analysis package, I usually leave the Depends/Imports/Suggests blank and just load whatever analysis packages I need in an RMarkdown file that lives in the `docs/` directory.


### A Simple Analysis Package
I find it is easiest to use RStudio to start a new package via `File -> New Project ...` and then start a project in a `new directory` and finally select that we want a new `R package`.

Alternatively we could use the `usethis::create_package()` function to build the minimal package. 

```r
usethis::create_package('~/GitHub/TestPackage')  # replace the path to where you want it...
```

Once the package is created:

1. Put any `.csv` or `.xls` data files you have in `data-raw/` subdirectory.  In that same directory, create a R script or Rmarkdown file that reads the data in, cleans it up by renaming columns, or whatever.  An example R script might look something like this:
    
    ```text
    library(tidyverse)
    
    # Read in the data.  Do some cleaning/verification
    MaxTemp <- read.csv('data-raw/FlagMaxTemp.csv') %>%
      gather('DOM', 'MaxTemp', X1:X31) %>%            
      drop_na() %>%
      mutate(DOM = str_remove(DOM, fixed('X')) ) %>%  
      mutate(Date = lubridate::ymd( paste( Year, Month, DOM )) ) %>%
      select(Date, MaxTemp)
    
    # Save the data frame to the data/ directory as MaxTemp.rda
    usethis::use_data(MaxTemp)
    ```

2. In the `R/` directory, create file `MaxTemp.R` and when the package is built, this will document the dataset.
    
    ```text
    #' A time series of daily maximum temperatures in Flagstaff, AZ. 
    #' 
    #' @format a data frame with 10882 observations 
    #' \describe{
    #'   \item{Date}{The date of observation as a POSIX date format.}
    #'   \item{MaxTemp}{Daily maximum temperature in degrees Farhenheit.}
    #' }
    #' @source \url{www.ncdc.noaa.gov}
    "MaxTemp"
    ```

3. Build the package by going to `Build` tab.
    a) Click the `More` and select `Document` to create the data frame documentation.
    b) Click the `Install and Restart` to build the package.

4. Create the `docs/` directory and then create a RMarkdown file that does some analysis.
    
    ```text
    ---
    title: "My Awesome Analysis"
    author: "Derek Sonderegger"
    date: "9/18/2019"
    output: html_document
    ---
    
    This Rmarkdown file will do the analysis.
    
    ```{r, eval=FALSE}
    library(TestPackage)   # load TestPackage, which includes MaxTemp data frame.
    library(ggplot2)
    
    ggplot(MaxTemp, aex(x=Date, y=MaxTemp)) +
      geom_line()
    ```
    
    We see that the daily max temperature in Flagstaff varies quite a lot.
    ```




## Sharing your Package
The last step to a package is being able to share it with other people. We could either wrap up the package into a `.tar.gz` file or we could save the package to ssome version control platform like `GitHub`. For packages that are in a stable form and need to be available via `CRAN` or Bioconductor, then building a `.tar.gz` file is important. However when a package is just meant for yourself and your collaborators, I prefer to save the package to `GitHub`.

I have several packages available on my `GitHub` account.  I have a repository 
[https://github.com/dereksonderegger/TestPackage](https://github.com/dereksonderegger/TestPackage) that demonstrates a very simple package. To install this package, we can install it directly using the following:


```r
devtools::install_github('dereksonderegger/TestPackage')
```


If you chose to share your package with others by sharing a `.tar.gz` file, then create the file using the `Build` tab and `More -> Build Source Package`. Then to install the package, the user will run the R command

```r
install.packages('TestPackage_0.0.0.1.tar.gz', repos=NULL, type='source')
```


## Exercises

1. Build a package that contains a dataset that gives weather information at Flagstaff's Pulliam Airport from 1950 to 2019. I have the data and metadata on my GitHub site and I downloaded the data on 9-19-19 from https://www.ncdc.noaa.gov/cdo-web/search. In the data, there are a bunch of columns that contain attribute information about the preceding column. I don't think those are helpful, or at least the metadata didn't explain how to interpret them. So remove those. Many of the later columns have values that are exclusively ones or zeros.  I believe those indicate if the weather phenomena was present that day. Presumably a `1` is a yes, but I don't know that. When I downloaded the data, I asked for "standard" units, so precipitation and snow amounts should be in inches, and temperature should be in Farenheit.
    a) Create a new package named `YourName_FlagWeather`. In the package, create the `data-raw/` directory and  place the data and metadata there.
    b) Build an R-script that reads in the data, does any necessary cleaning. Call your resulting data frame `Flagstaff_Weather` and save a `.rda` file to the `data/` directory using the cammand `usethis::use_data(Flagstaff_Weather)`
    c) In the `R/` directory, create a file `Flagstaff_Weather.R` that documents where the data came from and what each of the columns mean.
    d) Cause `roxygen2` to build the appropriate documentation files. Use the `Build` tab, then `More -> Document`.
    e) Load your package and restart your session of R, again using the `Build tab`.
    f) Create a new directory in your package called `docs/`. In that directory create a RMarkdown file that loads your package and uses the weather data to make a few graphs of weather phenomena over time.
    g) Suppose that we decided to change something in the data and we need to rebuild the package. 
        i) Changing the name of one of the columns in your cleaning script.  
        ii) Re-run the cleaning script and the `usethis::use_data` command. 
        iii) Reinstall the package using the `Build` tab and `Install and Restart`.
        iv) Verify that the `Flagstaff_Weather` object has changed.
        v) Verify that the documentation hasn't changed yet.
        vi) Update the documentation file for the dataset and re-run the documentation routine.
        vii) Reinstall the package and check that the documentation is now correct.
    h) Now save the package as one file by building a source package using the `Build` tab, `More -> Build Source Package`. This will create a `.tar.gz` file that you can easily upload to Bblearn. 
